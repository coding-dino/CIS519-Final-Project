# -*- coding: utf-8 -*-
"""CIS 519 Final Project Notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Sr2k6BbemB20-rBdDHsA7ka1O0LLk9z_

# CIS 519 Final Project: Predicting Future Stock Price Movement with Machine Learning
"""

# import modules

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os, math
from pylab import rcParams
import random 

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV
from sklearn.feature_selection import RFECV, SelectFromModel, SelectKBest

from sklearn.neighbors import KNeighborsClassifier
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import SGDRegressor
from sklearn.ensemble import RandomForestClassifier

from sklearn import metrics
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.metrics import f1_score

import torch
import torch.nn as nn
import torch.utils.tensorboard as tb
import torch.nn.functional as F
import torch.optim as optim
from tqdm.notebook import tqdm
import torchvision as thv
from torch.utils.data import DataLoader, TensorDataset
from torch.optim.lr_scheduler import StepLR

from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

from google.colab import drive
drive.mount('/content/drive')

"""# Import Dataset, Preprocess"""

# import dataset from Google Drive
df_aapl = pd.read_csv('/content/drive/Shareddrives/CIS 519 project/AAPL.csv')
df_aapl

def visualize(df):
  plt.figure(figsize = (25,9))
  plt.plot(df[['Close(t)']])
  plt.xticks(range(0,df.shape[0],500),df['Date'].loc[::500],rotation=45)
  plt.title("Apple (AAPL) Closing Price",fontsize=20, fontweight='bold')
  plt.xlabel('Date',fontsize=15)
  plt.ylabel('Close Price (USD)',fontsize=15)
  plt.show()

visualize(df_aapl)

# pre-processing
def preprocess(df):
    '''
    Args:
        df: dataset to preprocess

    Returns: 
        preprocessed dataset
    '''

    # add classifier column "Movement" that shows the movement of the closing price "Close(t)" from Date t to Date t+1
    # 1 indicates a higher closing price the next day & -1 indicates a lower closing price the next day
    df["Movement Next Day"] = np.where(df['Close(t)'].shift(-1) > df['Close(t)'],1,-1)

    # drop NA 
    df = df.dropna()

    # remove outlier, 2008-09 Financial Crisis: remove data from January 1, 2008 - December 31, 2009 
    df = df.loc[(df['Date'] < '2008-01-01') | (df['Date'] > '2009-12-31')]

    # remove outlier, 'Covid Market Crash': remove data from March 1, 2020 - April 30, 2020
    df = df.loc[(df['Date'] < '2020-03-01') | (df['Date'] > '2020-04-30')]

    # drop unnecessary columns
    df = df.drop(columns = ['Date','Date_col',	'Day',	'DayofWeek',	'DayofYear',	'Week', 'Is_month_end',	'Is_month_start',	'Is_quarter_end',	'Is_quarter_start',	'Is_year_end',	'Is_year_start',	'Is_leap_year', 'Year',	'Month'])

    return df

# pre-process the dataset
df_aapl = preprocess(df_aapl)
df_aapl

"""# Baseline Models for Classification
kNN

Decision Tree

## kNN Classifier
"""

# kNN Classifier
def knn_classifier(df, k):
    '''
    Args:
        df: Dataset to run kNN Classifier on
        k: Number of neighbors to use for kneighbors queries.

    Returns:
    '''

    # define features X and labels y
    X = df.loc[:, df_aapl.columns != 'Movement Next Day']
    y = df['Movement Next Day']

    # split dataset into training and testing set
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) 

    
    # define model
    clf = KNeighborsClassifier(n_neighbors = k) 

    # train the model
    clf = clf.fit(X_train, y_train)

    # predict
    y_train_pred = clf.predict(X_train)
    y_test_pred = clf.predict(X_test)

    # model performance
    accuracy_train = accuracy_score(y_train, y_train_pred)
    accuracy_test = accuracy_score(y_test, y_test_pred)
    print('Train_data Accuracy for k = ', k, ': %.2f' %accuracy_train)
    print('Test_data Accuracy for k = ', k, ': %.2f' %accuracy_test)
    print()

# run k-NN with various k values
print('kNN classifier')
print()
k_values = [1, 3, 5, 15, 30, 50]
for k in k_values:
  knn_classifier(df_aapl, k=k)

"""## Decision Tree Classifier"""

# Decision Tree Classifier
def dt_classifier(df):
    '''
    Args:
        df: Dataset to run decision tree classifier on

    Returns:
    '''

    # predictors used are classical indicators for trend
    predictors = ['MA10','MA50','MA200','EMA10','EMA50','EMA200', 'ATR', 'ADX','RSI','MACD','MACD_EMA']

    # define features X and labels y
    X = df[predictors]
    y = df['Movement Next Day']


    # split dataset into training and testing set
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y) 

    # define model
    clf = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_leaf=6)

    # fit the model
    clf = clf.fit(X_train, y_train)
  
    # predict
    y_pred = clf.predict(X_test)

    # model performance
    print()
    report = classification_report(y_test, y_pred)
    print(report)

# run decision tree classifier
print('Decision Tree Classifier')
print()
dt_classifier(df_aapl)

"""# Main Models for Classification

Logistic Regression 

Neural Networks

Random Forest

## Logistic Regression Classifier
"""

# Logistic Regression Classifier
def logistic_regression(df): 
    '''
    Args:
        df: Dataset to run logistic regression on

    Returns:
    '''

    # define features X and labels y
    X = df.loc[:, df_aapl.columns != 'Movement Next Day']
    y = df['Movement Next Day']

    # split dataset into training and testing set
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) 
    
    # define model
    clf = LogisticRegression()

    # train the model
    clf = clf.fit(X_train, y_train)

    print('Logistic Regression Classifier')
    print()
    # predict
    print('Calculate probabilities of the class for test data')
    probability = clf.predict_proba(X_test)
    print(probability)  
    print()

    # 1 if value in second column >= 0.5, -1 if it is < 0.5
    print('Predicted class of test data')
    predicted = clf.predict(X_test)
    print(predicted)
    print()

    # model performance
    print('Confusion Matrix')
    print(metrics.confusion_matrix(y_test, predicted))
    print()

    print('Classification Report')
    print(metrics.classification_report(y_test, predicted))
    print()

    print('Model Accuracy')
    print(clf.score(X_test,y_test))
    print()

    print('Cross-Validation')
    cross_val = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)
    print(cross_val)
    print()
    print('Cross-Validation Mean')
    print(cross_val.mean())

# run logistic regression
logistic_regression(df_aapl)

"""## Random Forest"""

def randomforest(df):
    regr = RandomForestClassifier(n_estimators=200, max_depth=7, random_state=0)

    # define features X and labels y
    X = df.loc[:, df_aapl.columns != 'Movement Next Day']
    y = df['Movement Next Day']

    # split dataset into training and testing set
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) 
    model = regr.fit(X_train, y_train)
    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
    max_features = ['auto','sqrt']
    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
    max_depth.append(None)
    min_samples_split = [2, 5, 10]
    min_samples_leaf = [1, 2, 4]
    bootstrap = [True, False]
    random_grid = {'n_estimators': n_estimators,
                  'max_features': max_features,
                  'max_depth': max_depth,
                  'min_samples_split': min_samples_split,
                  'min_samples_leaf': min_samples_leaf,
                  'bootstrap': bootstrap}

    rf_random = RandomizedSearchCV(estimator=regr, param_distributions=random_grid, n_iter=20, cv = 3, verbose=2, random_state=42, n_jobs=-1)
    rf_random.fit(X_train, y_train)

    report = classification_report(y_test, rf_random.predict(X_test))
    print(report)

randomforest(df_aapl)